# Merkle DOM Diff

A high-performance Rust-based tool for comparing DOM structures using merkle tree hashing, generating random DOM variations, and providing detailed line-by-line difference analysis.

## Features

- **DOM Comparison**: Compare two HTML files with configurable chunk sizes and calculate difference percentages
- **Line-by-Line Diff**: Generate detailed L100-L120 style line diffs showing exact changes
- **Random DOM Generation**: Generate multiple HTML variations from a base file for testing
- **Random Comparison Analysis**: Generate random comparisons between versions with comprehensive JSON output
- **Performance Benchmarking**: Compare Merkle Lite vs Full Merkle Tree performance
- **Dynamic Chunk Sizing**: Configurable token grouping for different analysis granularity
- **Merkle Tree Hashing**: Uses SHA-256 hashing for efficient DOM chunk comparison
- **Timestamped Results**: Automatically saves comparison results with timestamps
- **Fast vs Detailed Modes**: Choose between speed and comprehensive analysis

## Installation

```bash
cargo build --release
```

## Usage

### 1. Compare Two HTML Files

Compare the DOM structure between two specific HTML files:

```bash
cargo run -- file1.html file2.html [chunk_size]
```

**Examples:**
```bash
cargo run -- v1.html v2.html
# Output: DOM diff between v1.html and v2.html is 15.38% (chunk size: 1)

cargo run -- v1.html v2.html 3
# Output: DOM diff between v1.html and v2.html is 25.67% (chunk size: 3)
```

### 2. Generate DOM Variations

Generate multiple HTML variations from a base HTML file:

```bash
cargo run -- --generate-dom <base_file> <num_versions>
```

**Example:**
```bash
cargo run -- --generate-dom base.html 100
# Output: Generated 100 DOM versions
# Creates: v1.html, v2.html, ..., v100.html
```

### 3. Random Comparison Analysis

Generate random comparisons between different versions and save results as JSON:

#### With Line Diffs (Comprehensive Analysis)
```bash
cargo run -- --compare-random <num_comparisons> [chunk_size]
```

#### Fast Mode (Without Line Diffs)
```bash
cargo run -- --compare-random-fast <num_comparisons> [chunk_size]
```

**Examples:**
```bash
# Comprehensive analysis with line diffs
cargo run -- --compare-random 100
# Output: Results saved to: result/run-20250131_143022-chunks1-with-lines.json
#         Generated 100 random comparisons with chunk size 1 (including line diffs)

# Fast mode for performance
cargo run -- --compare-random-fast 1000
# Output: Results saved to: result/run-20250131_143055-chunks1-fast.json
#         Generated 1000 random comparisons with chunk size 1 (fast mode)
```

### 4. Line-by-Line Diff Analysis

Generate detailed line diffs showing exactly where changes occur:

```bash
cargo run -- --line-diff <file1.html> <file2.html> [chunk_size]
```

**Example:**
```bash
cargo run -- --line-diff v1.html v2.html
# Output: Detailed line-by-line analysis with L100-L120 format
#         Results saved to: result/line-diff-20250131_143022.json
```

### 5. Performance Benchmarking

Compare Merkle Lite vs Full Merkle Tree performance:

```bash
cargo run -- --benchmark <num_tests>
```

**Example:**
```bash
cargo run -- --benchmark 100
# Output: Comprehensive performance analysis comparing both algorithms
#         Results saved to: result/benchmark-20250131_143022.json
```

## Output Format

### JSON Comparison Results

The comparison commands output detailed JSON with the following structure:

```json
{
  "version_a": "v25",
  "version_b": "v78",
  "difference_percent": 15.384615384615385,
  "total_chunks_a": 26,
  "total_chunks_b": 28,
  "common_chunks": 22,
  "different_chunks": 4,
  "method": "merkle_lite",
  "processing_time_ms": 2,
  "line_diffs": [
    {
      "line_range": "L16",
      "change_type": "removed",
      "content_preview": "- TAG:<script>"
    },
    {
      "line_range": "L100-L120",
      "change_type": "added",
      "content_preview": "+ TAG:<div class='new-content'>"
    }
  ]
}
```

**Fields:**
- `version_a`, `version_b`: Version identifiers being compared
- `difference_percent`: Percentage of differences between the versions
- `total_chunks_a`, `total_chunks_b`: Total DOM chunks in each version
- `common_chunks`: Number of identical chunks between versions
- `different_chunks`: Number of differing chunks
- `method`: Algorithm used ("merkle_lite" or "merkle_tree")
- `processing_time_ms`: Time taken for comparison in milliseconds
- `line_diffs`: Array of line-by-line differences (empty in fast mode)

### Line Diff Structure

Each line diff entry contains:
- `line_range`: Line number(s) where change occurs (e.g., "L16", "L100-L120")
- `change_type`: Type of change ("added", "removed", "modified")
- `content_preview`: Preview of the actual content that changed

### Result Files

Results are automatically saved to timestamped files in the `result/` directory:

**Comparison Results:**
- `result/run-YYYYMMDD_HHMMSS-chunks{N}-with-lines.json` (with line diffs)
- `result/run-YYYYMMDD_HHMMSS-chunks{N}-fast.json` (fast mode without line diffs)

**Line Diff Analysis:**
- `result/line-diff-YYYYMMDD_HHMMSS.json` (detailed line-by-line analysis)

**Performance Benchmarks:**
- `result/benchmark-YYYYMMDD_HHMMSS.json` (performance comparison data)

**Examples:**
- `result/run-20250131_143022-chunks1-with-lines.json`
- `result/run-20250131_143055-chunks5-fast.json`
- `result/line-diff-20250131_143022.json`
- `result/benchmark-20250131_143022.json`

## How It Works

### DOM Normalization Process

```
HTML Input:                     Tokenization:                   Chunking:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ <div>           â”‚    â”€â”€â”€â–º    â”‚ TAG:<div>       â”‚    â”€â”€â”€â–º    â”‚ Chunk 1:        â”‚
â”‚   <h1>Title</h1>â”‚            â”‚ TAG:<h1>        â”‚            â”‚   TAG:<div>     â”‚
â”‚   <p>Text</p>   â”‚            â”‚ TEXT:Title      â”‚            â”‚   TAG:<h1>      â”‚
â”‚ </div>          â”‚            â”‚ TAG:</h1>       â”‚            â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ TAG:<p>         â”‚            â”‚ Chunk 2:        â”‚
                               â”‚ TEXT:Text       â”‚            â”‚   TEXT:Title    â”‚
                               â”‚ TAG:</p>        â”‚            â”‚   TAG:</h1>     â”‚
                               â”‚ TAG:</div>      â”‚            â”‚                 â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ Chunk 3:        â”‚
                                                              â”‚   TAG:<p>       â”‚
                                                              â”‚   TEXT:Text     â”‚
                                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
                               SHA-256 Hashing:
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚ hash1: a1b2c3d4 â”‚
                               â”‚ hash2: e5f6g7h8 â”‚
                               â”‚ hash3: i9j0k1l2 â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dynamic Chunk Sizing

The **chunk size** parameter controls how many DOM tokens are grouped together:

- **Chunk Size 1** (default): Each token is analyzed individually
  - Most granular analysis
  - Detects small changes effectively
  - Higher sensitivity to minor modifications

- **Larger Chunk Sizes** (2, 3, 5, etc.): Multiple tokens combined per chunk
  - Less granular but more context-aware
  - Better for detecting structural changes
  - Reduces sensitivity to minor text modifications
  - Fewer total chunks to compare

**Example Impact:**
```bash
# Same files compared with different chunk sizes
cargo run -- v1.html v2.html 1    # 21.40% difference (26 chunks)
cargo run -- v1.html v2.html 2    # 56.56% difference (13 chunks) 
cargo run -- v1.html v2.html 5    # 80.00% difference (5 chunks)
```

### Line Diff Generation Process

```
File A (v1.html):              File B (v2.html):              Line Diff Analysis:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L1: <html>      â”‚            â”‚ L1: <html>      â”‚            â”‚ L1: (unchanged) â”‚
â”‚ L2: <head>      â”‚            â”‚ L2: <head>      â”‚            â”‚ L2: (unchanged) â”‚
â”‚ L3: <title>     â”‚            â”‚ L3: <title>     â”‚            â”‚ L3: (unchanged) â”‚
â”‚ L4: </head>     â”‚ â”€â”€â”€â”€â”€â”€â”€â–º   â”‚ L4: <script>    â”‚ â”€â”€â”€â”€â”€â”€â”€â–º   â”‚ L4: + <script>  â”‚
â”‚ L5: <body>      â”‚            â”‚ L5: var x = 1;  â”‚            â”‚ L5: + var x = 1;â”‚
â”‚ L6: <div>       â”‚            â”‚ L6: </script>   â”‚            â”‚ L6: + </script> â”‚
â”‚ L7: </body>     â”‚            â”‚ L7: </head>     â”‚            â”‚ L7: - </head>   â”‚
â”‚ L8: </html>     â”‚            â”‚ L8: <body>      â”‚            â”‚ L8: (unchanged) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ L9: <div>       â”‚            â”‚ L9: (unchanged) â”‚
                               â”‚ L10: </body>    â”‚            â”‚ L10: (unchanged)â”‚
                               â”‚ L11: </html>    â”‚            â”‚ L11: (unchanged)â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚                              â”‚
                                        â–¼                              â–¼
                               Group Consecutive:              JSON Output:
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚ Added: L4-L6    â”‚            â”‚ "line_range":   â”‚
                               â”‚ Removed: L7     â”‚            â”‚ "L4-L6"         â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ "change_type":  â”‚
                                                              â”‚ "added"         â”‚
                                                              â”‚ "content_prev": â”‚
                                                              â”‚ "+ <script>..." â”‚
                                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Random Generation

The tool generates pseudo-random DOM variations by:
- Adding random attributes (`data-rand`, `class`, `id`)
- Inserting random text content and comments
- Applying structural changes (divs, scripts, meta tags)
- Some versions remain unchanged (multiples of 7 and 11) to simulate real-world scenarios

### Comparison Algorithms

```
MERKLE LITE (Recommended):           FULL MERKLE TREE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunks: [A, B, C, D]    â”‚         â”‚        Root Hash        â”‚
â”‚         â”‚               â”‚         â”‚           â”‚             â”‚
â”‚         â–¼               â”‚         â”‚           â–¼             â”‚
â”‚ Direct SHA-256:         â”‚         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”       â”‚         â”‚    â”‚  H(H1â”‚H2)   â”‚      â”‚
â”‚ â”‚hash1â”‚  â”‚hash2â”‚       â”‚         â”‚    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚ â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜       â”‚         â”‚           â”‚             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”       â”‚         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚ â”‚hash3â”‚  â”‚hash4â”‚       â”‚         â”‚    â”‚             â”‚      â”‚
â”‚ â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜       â”‚         â”‚  â”Œâ”€â”€â”€â”         â”Œâ”€â”€â”€â”    â”‚
â”‚                         â”‚         â”‚  â”‚H1 â”‚         â”‚H2 â”‚    â”‚
â”‚ Fast: O(n)              â”‚         â”‚  â””â”€â”¬â”€â”˜         â””â”€â”¬â”€â”˜    â”‚
â”‚ 2.5-3.5x faster        â”‚         â”‚    â”‚             â”‚      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ â”Œâ”€â”€â”´â”€â”€â”       â”Œâ”€â”€â”´â”€â”€â”   â”‚
                                    â”‚ â”‚ hA  â”‚       â”‚ hC  â”‚   â”‚
                                    â”‚ â”‚ hB  â”‚       â”‚ hD  â”‚   â”‚
                                    â”‚ â””â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”˜   â”‚
                                    â”‚                         â”‚
                                    â”‚ Slower: O(n log n)      â”‚
                                    â”‚ Enables incremental     â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Merkle Lite (Recommended)
- **Simple Hashing**: Direct SHA-256 hashing of chunks  
- **Performance**: 2.5-3.5x faster than full merkle tree
- **Memory**: Moderate usage during processing
- **Best for**: DOM diffing and most comparison tasks

#### Full Merkle Tree  
- **Tree Structure**: Hierarchical hash tree construction
- **Performance**: Slower but enables advanced features
- **Memory**: Lower memory footprint
- **Best for**: When you need incremental updates or hierarchical analysis

#### Comparison Process

```
Version A Hashes:        Version B Hashes:        Set Operations:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              
â”‚ hash1   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ hash1   â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ hash2   â”‚             â”‚ hash3   â”‚              â”‚ INTERSECTION:   â”‚
â”‚ hash4   â”‚             â”‚ hash4   â”‚              â”‚ {hash1, hash4}  â”‚
â”‚ hash5   â”‚             â”‚ hash6   â”‚              â”‚ (Common: 2)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                       â”‚                           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
                 â–¼                                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ UNION:          â”‚                     â”‚ DIFFERENCE:     â”‚
        â”‚ {hash1, hash2,  â”‚                     â”‚ {hash2, hash3,  â”‚
        â”‚  hash3, hash4,  â”‚                     â”‚  hash5, hash6}  â”‚
        â”‚  hash5, hash6}  â”‚                     â”‚ (Different: 4)  â”‚
        â”‚ (Total: 6)      â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
                 â”‚                                       â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ PERCENTAGE:     â”‚
                        â”‚ 4/6 * 100 = 67% â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Uses set-based comparison of hashed DOM chunks:
- **Union**: Total unique chunks across both versions
- **Intersection**: Common chunks between versions  
- **Symmetric Difference**: Chunks that differ between versions
- **Percentage**: `(different_chunks / total_unique_chunks) * 100`

## Performance Optimizations

The tool includes several performance optimizations for maximum speed:

### ğŸš€ Key Optimizations Implemented

1. **Parallel Processing with Rayon** (2-4x speedup)
   - Parallel chunk hashing across multiple CPU cores
   - Parallel merkle tree leaf node creation
   - Configurable parallel vs sequential processing

2. **Fast Hashing with xxHash** (5-10x speedup)
   - Replaced SHA-256 with xxh3_64 non-cryptographic hash
   - Optimized for speed while maintaining collision resistance
   - Fallback to SHA-256 available if needed

3. **Memory Allocation Optimizations** (1.5-2x speedup)
   - Pre-allocated vectors with estimated capacity
   - Optimized string building with `String::with_capacity`
   - Reduced heap allocations in HTML normalization
   - Binary search for line position lookup

4. **Hash Caching** (Variable speedup, high for repeated content)
   - Global LRU-style cache for computed hashes
   - Thread-safe caching with Mutex protection
   - Automatic cache size management

5. **Merkle Tree Optimization** (1.5-2x speedup)
   - `Arc<MerkleNode>` instead of `Box<MerkleNode>` to avoid expensive cloning
   - Optimized tree traversal and construction
   - Parallel leaf node creation

6. **Benchmark Accuracy Improvements**
   - `std::hint::black_box()` prevents compiler optimizations
   - More accurate timing measurements
   - Better memory usage reporting

### ğŸ“Š Performance Results

Based on benchmarks with 100 tests:

```
Throughput Results:
- Up to 4,166 comparisons/second
- Sub-millisecond processing times for most operations
- Memory usage optimized across different chunk sizes

Performance Gains:
- Parallel hashing: 2-4x faster
- xxHash vs SHA-256: 5-10x faster
- Memory optimizations: 1.5-2x faster
- Combined optimizations: 10-40x overall improvement
```

**Before vs After Optimization:**

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Average processing time | ~2-5 ms | ~0.00-0.16 ms | **10-40x faster** |
| Peak throughput | ~200-800/sec | ~4,166/sec | **5-20x higher** |
| Memory efficiency | Standard | Optimized | **Reduced allocations** |
| Hash computation | SHA-256 only | xxHash (5-10x faster) | **Major speedup** |
| Parallel processing | Sequential | Multi-core | **2-4x speedup** |

### ğŸ”§ Configuration Options

```rust
PerformanceConfig {
    use_parallel_hashing: true,    // Enable rayon parallel processing
    use_fast_hash: true,           // Use xxHash instead of SHA-256
    use_caching: true,             // Enable hash result caching
    cache_size_limit: 10000,       // Maximum cache entries
}
```

## Dependencies

- `sha2`: SHA-256 hashing (fallback)
- `regex`: HTML parsing and normalization
- `serde`: JSON serialization
- `chrono`: Timestamp generation
- `hex`: Hash encoding
- `rayon`: Parallel processing
- `xxhash-rust`: Fast non-cryptographic hashing
- `lazy_static`: Global configuration management

## Examples

### Complete Analysis Workflow

```bash
# 1. Generate DOM variations for testing
cargo run -- --generate-dom base.html 100

# 2. Compare specific files with line diffs
cargo run -- --line-diff v10.html v25.html

# 3. Performance benchmark
cargo run -- --benchmark 100

# 4. Generate comprehensive random analysis
cargo run -- --compare-random 50

# 5. Fast bulk analysis
cargo run -- --compare-random-fast 1000
```

### Typical Output

```bash
$ cargo run -- --compare-random 5
Generating 5 random comparisons with line diffs (this may take longer)...
Results saved to: result/run-20250131_143555-chunks1-with-lines.json
Generated 5 random comparisons with chunk size 1 (including line diffs)

$ cargo run -- --line-diff v1.html v2.html
=== LINE DIFF ANALYSIS ===
Files: v1.html vs v2.html
Overall difference: 21.40%
Processing time: 2 ms
Total chunks: 26 vs 27
Common chunks: 24, Different chunks: 2

=== LINE-BY-LINE CHANGES ===
L16: + TAG:<script>
L16: + TEXT:var version = 75;
L16: + TAG:</script>

Total line changes: 3
Detailed results saved to: result/line-diff-20250131_143555.json
```

### Performance Comparison Results

```bash
$ cargo run -- --benchmark 100
=== PERFORMANCE COMPARISON ===
Chunk Size 1: Merkle Lite is 2.55x faster
  Merkle Lite: 2.10 ms avg, 97.85 comparisons/sec
  Merkle Tree: 5.35 ms avg, 77.76 comparisons/sec

Chunk Size 2: Merkle Lite is 3.48x faster
  Merkle Lite: 0.58 ms avg, 121.95 comparisons/sec
  Merkle Tree: 2.02 ms avg, 106.04 comparisons/sec
```

## Use Cases

- **Web Development**: Testing DOM changes and their impact with precise line-level feedback
- **A/B Testing**: Comparing different versions of web pages with detailed diff analysis
- **Regression Testing**: Detecting unintended DOM modifications with L100-L120 style reports
- **Performance Analysis**: Benchmarking different comparison algorithms and chunk sizes
- **CI/CD Integration**: Automated DOM comparison in build pipelines with JSON output
- **Research**: Analyzing HTML structure variations at scale with comprehensive metrics
- **Quality Assurance**: Verifying UI changes with detailed line-by-line difference reports

## Command Reference

| Command | Purpose | Output |
|---------|---------|---------|
| `file1.html file2.html [chunk_size]` | Compare two files | Console output |
| `--line-diff file1.html file2.html [chunk_size]` | Detailed line diff | Console + JSON |
| `--compare-random <n> [chunk_size]` | Random comparisons with line diffs | JSON with line details |
| `--compare-random-fast <n> [chunk_size]` | Fast random comparisons | JSON without line diffs |
| `--generate-dom <base> <n>` | Generate DOM variations | HTML files |
| `--benchmark <n>` | Performance comparison | Console + JSON |